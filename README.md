(EN)ğŸ›¡ï¸ SentinelAnalyzerProject: System Architecture
1. Data Collection Layer (Python Sniffer)
This layer acts as the "sensory organ," capturing raw network packets and integrating them into the system.

Packet Capture: Developing a script using Scapy or PyShark libraries to monitor network traffic.

Feature Extraction: Converting raw data (IP, port, packet size, protocol, etc.) into numerical features compatible with Machine Learning models.

Kafka Producer: Streaming processed data to the Apache Kafka raw-traffic topic with low latency.

2. Messaging and Queuing Layer (Apache Kafka & Redis)
The "central nervous system" that ensures modularity and scalability.

Kafka Cluster Setup: Deploying Kafka and Zookeeper (or KRaft) using Docker.

Speed and Buffering: Queuing high-volume data from Python before it is passed to the Java backend.

Fast Access (Redis): A caching layer to provide real-time statistics or the latest detected anomalies to the Dashboard instantly.

3. Analysis and Decision Mechanism (Python ML)
The "brain" of the system, responsible for determining whether the data is "abnormal."

Model Training: Teaching the system normal traffic patterns using Scikit-learn (e.g., via Isolation Forest or Random Forest algorithms).

Real-time Prediction: Processing incoming Kafka data through the model to label it as "Attack/Anomaly" or "Normal."

Result Transmission: Publishing analysis results back to the Kafka alerts topic.

4. Processing and Visualization Layer (Java 21 & Spring Boot)
The component that handles high-density data processing using Java 21â€™s Virtual Threads (Project Loom).

Consumption via Virtual Threads: Writing Kafka consumers that process thousands of alerts in parallel without exhausting system resources.

API Development: Creating a REST or WebSocket API with Spring Boot to expose anomaly data.

Dashboard: Developing a user interface featuring real-time charts (speed, traffic density, anomaly counts).

5. Optimization and Deployment (Docker & Resource Limiting)
The stage where the project gains "Embedded Awareness."

Containerization: Writing Dockerfiles for each module (Java, Python, Kafka).

Resource Constraints: Testing performance on low-end hardware (like Raspberry Pi) by setting cpus: 0.5 and memory: 512M limits in Docker Compose.

Performance Benchmarking: Measuring the advantages of Java Virtual Threads over traditional threading models under restricted resource conditions.

(TR)ğŸ›¡ï¸ SentinelAnalyzerProject: 
1. Katman: Veri Toplama (Python Sniffer)
Bu katman, aÄŸdaki ham paketleri yakalayÄ±p sisteme dahil eden "duyu organÄ±dÄ±r".

Paket Yakalama: Scapy veya PyShark kÃ¼tÃ¼phanelerini kullanarak aÄŸ trafiÄŸini dinleyen bir script yazÄ±lmasÄ±.

Ã–zellik Ã‡Ä±karÄ±mÄ± (Feature Extraction): Ham veriden (IP, port, paket boyutu, protokol vb.) ML modelinin anlayabileceÄŸi sayÄ±sal verilerin oluÅŸturulmasÄ±.

Kafka Producer: Ä°ÅŸlenen bu verilerin dÃ¼ÅŸÃ¼k gecikmeyle Apache Kafka'ya "raw-traffic" topic'i Ã¼zerinden gÃ¶nderilmesi.

2. Katman: MesajlaÅŸma ve Kuyruk (Apache Kafka & Redis)
Sistemin modÃ¼lerliÄŸini ve Ã¶lÃ§eklenebilirliÄŸini saÄŸlayan merkezi sinir sistemidir.

Kafka Cluster Kurulumu: Docker Ã¼zerinde Kafka ve Zookeeper (veya KRaft) ayaÄŸa kaldÄ±rÄ±lmasÄ±.

HÄ±z ve Tamponlama: Python'dan gelen yoÄŸun verinin Java tarafÄ±na geÃ§meden Ã¶nce kuyruÄŸa alÄ±nmasÄ±.

HÄ±zlÄ± EriÅŸim (Redis): AnlÄ±k istatistiklerin veya son tespit edilen anomalilerin hÄ±zlÄ±ca Dashboard'a sunulmasÄ± iÃ§in Ã¶nbellekleme katmanÄ±.

3. Katman: Analiz ve Karar MekanizmasÄ± (Python ML)
Verinin "anormal" olup olmadÄ±ÄŸÄ±na karar veren beyin kÄ±smÄ±dÄ±r.

Model EÄŸitimi: Scikit-learn ile (Ã¶rneÄŸin Isolation Forest veya Random Forest kullanarak) normal trafik desenlerinin Ã¶ÄŸretilmesi.

GerÃ§ek ZamanlÄ± Tahmin: Kafka'dan gelen verilerin modele sokularak "SaldÄ±rÄ±/Anomali" veya "Normal" olarak etiketlenmesi.

SonuÃ§ Ä°letimi: Analiz sonuÃ§larÄ±nÄ±n tekrar Kafka'daki "alerts" topic'ine basÄ±lmasÄ±.

4. Katman: Ä°ÅŸleme ve GÃ¶rselleÅŸtirme (Java 21 & Spring Boot)
Java 21'in Virtual Threads (Project Loom) Ã¶zelliÄŸini kullanarak yÃ¼ksek yoÄŸunluklu veriyi iÅŸleme kÄ±smÄ±dÄ±r.

Virtual Threads ile TÃ¼ketim: Kafka'dan gelen binlerce alarmÄ±, sistem kaynaklarÄ±nÄ± tÃ¼ketmeden paralel olarak iÅŸleyecek "Consumer"larÄ±n yazÄ±lmasÄ±.

API GeliÅŸtirme: Spring Boot ile anomali verilerini dÄ±ÅŸ dÃ¼nyaya sunan bir REST veya WebSocket API oluÅŸturulmasÄ±.

Dashboard: GerÃ§ek zamanlÄ± grafikler (hÄ±z, trafik yoÄŸunluÄŸu, anomali sayÄ±sÄ±) iÃ§eren bir arayÃ¼z geliÅŸtirilmesi.

5. Katman: Optimizasyon ve DaÄŸÄ±tÄ±m (Docker & Resource Limiting)
Projenin "GÃ¶mÃ¼lÃ¼ Sistem FarkÄ±ndalÄ±ÄŸÄ±" (Embedded Awareness) kazandÄ±ÄŸÄ± aÅŸamadÄ±r.

KonteynerleÅŸtirme: Her modÃ¼lÃ¼n (Java, Python, Kafka) Dockerfile'larÄ±nÄ±n yazÄ±lmasÄ±.

Kaynak KÄ±sÄ±tlama: Docker Compose Ã¼zerinde cpus: 0.5 ve memory: 512M gibi limitler koyarak, yazÄ±lÄ±mÄ±n dÃ¼ÅŸÃ¼k donanÄ±mlÄ± cihazlarda (Raspberry Pi gibi) nasÄ±l performans gÃ¶sterdiÄŸinin test edilmesi.

Performans Ä°yileÅŸtirme: KÄ±sÄ±tlÄ± kaynak altÄ±nda Java Virtual Threads kullanÄ±mÄ±nÄ±n geleneksel thread yapÄ±sÄ±na gÃ¶re avantajlarÄ±nÄ±n Ã¶lÃ§Ã¼mlenmesi.
